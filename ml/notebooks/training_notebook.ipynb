{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 1: Network Traffic Anomaly Detection - Training\n",
                "This notebook covers the data loading, cleaning, feature engineering, and training of an Isolation Forest model for AIOps-ready network telemetry analysis.\n",
                "\n",
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "from sklearn.ensemble import IsolationForest\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from google.colab import files\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data\n",
                "Upload the `network_traffic_data.csv` file from your local machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "uploaded = files.upload()\n",
                "df = pd.read_csv('network_traffic_data.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning & Feature Engineering\n",
                "We will clean the data and transform categorical features into a format suitable for the Isolation Forest algorithm."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values\n",
                "df['dns_query'] = df['dns_query'].fillna('none')\n",
                "df = df.dropna(subset=['source_ip', 'dest_ip', 'dest_port', 'protocol'])\n",
                "\n",
                "# Encoding Categorical Features\n",
                "le_protocol = LabelEncoder()\n",
                "df['protocol_enc'] = le_protocol.fit_transform(df['protocol'])\n",
                "\n",
                "# Scaling Numeric Features\n",
                "scaler = StandardScaler()\n",
                "numeric_features = ['dest_port', 'bytes_sent', 'bytes_recv']\n",
                "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
                "\n",
                "# Feature Selection Documentation:\n",
                "# - dest_port: Identifies target services, useful for detecting port scanning or lateral movement.\n",
                "# - bytes_sent/recv: Volume metrics are key to identifying data exfiltration (high sent) or command-and-control (low, periodic traffic).\n",
                "# - protocol_enc: Baseline behaviors differ significantly between TCP, UDP, and ICMP.\n",
                "\n",
                "features = numeric_features + ['protocol_enc']\n",
                "X = df[features]\n",
                "print(f\"Feature matrix shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Model\n",
                "We use **Isolation Forest**, an unsupervised learning algorithm that is effective at identifying anomalies by isolating observations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training Isolation Forest model...\")\n",
                "model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
                "model.fit(X)\n",
                "\n",
                "# Evaluate\n",
                "predictions = model.predict(X)\n",
                "df['anomaly_score'] = model.decision_function(X)\n",
                "df['is_anomaly'] = predictions\n",
                "\n",
                "anomaly_count = (predictions == -1).sum()\n",
                "print(f\"Detected {anomaly_count} anomalies out of {len(df)} records.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Export Artifacts\n",
                "Save the model and preprocessing objects for use in the REST API (Phase 2)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_artifacts = {\n",
                "    'model': model,\n",
                "    'scaler': scaler,\n",
                "    'le_protocol': le_protocol,\n",
                "    'features': features\n",
                "}\n",
                "\n",
                "artifact_path = 'anomaly_model.joblib'\n",
                "joblib.dump(model_artifacts, artifact_path)\n",
                "print(f\"Model saved to {artifact_path}\")\n",
                "\n",
                "# Download back to local machine\n",
                "files.download(artifact_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}